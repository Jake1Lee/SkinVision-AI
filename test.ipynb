{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0eea239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint keys: dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'val_acc'])\n",
      "\n",
      "Sample model state dict keys:\n",
      "1. conv1.weight\n",
      "2. bn1.weight\n",
      "3. bn1.bias\n",
      "4. bn1.running_mean\n",
      "5. bn1.running_var\n",
      "6. bn1.num_batches_tracked\n",
      "7. layer1.0.conv1.weight\n",
      "8. layer1.0.bn1.weight\n",
      "9. layer1.0.bn1.bias\n",
      "10. layer1.0.bn1.running_mean\n",
      "... and 314 more keys\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# First, let's inspect the checkpoint structure\n",
    "model_path = \"/mnt/c/Users/JakeLee/Desktop/PFE/App/SkinVision-AI/backend/models/resnet50_model.pth\"\n",
    "checkpoint = torch.load(model_path, map_location='cpu')\n",
    "\n",
    "print(\"Checkpoint keys:\", checkpoint.keys())\n",
    "print(\"\\nSample model state dict keys:\")\n",
    "if 'model_state_dict' in checkpoint:\n",
    "    model_keys = list(checkpoint['model_state_dict'].keys())\n",
    "    for i, key in enumerate(model_keys[:10]):\n",
    "        print(f\"{i+1}. {key}\")\n",
    "    print(f\"... and {len(model_keys)-10} more keys\")\n",
    "else:\n",
    "    # Direct model state dict\n",
    "    model_keys = list(checkpoint.keys())\n",
    "    for i, key in enumerate(model_keys[:10]):\n",
    "        print(f\"{i+1}. {key}\")\n",
    "    print(f\"... and {len(model_keys)-10} more keys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f854ae04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jl/miniconda3/lib/python3.13/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jl/miniconda3/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully on cuda\n",
      "Model was saved at epoch: 76\n",
      "Validation accuracy: 70.9730\n",
      "Loaded 40 class names\n",
      "Processing 100 images...\n",
      "Processing image 1/100: DERM_106035.jpg\n",
      "Processing image 2/100: DERM_110135.jpg\n",
      "Processing image 3/100: DERM_111637.jpg\n",
      "Processing image 4/100: DERM_125826.jpg\n",
      "Processing image 5/100: DERM_131011.jpg\n",
      "Processing image 6/100: DERM_134644.jpg\n",
      "Processing image 7/100: DERM_175311.jpg\n",
      "Processing image 8/100: DERM_181085.jpg\n",
      "Processing image 9/100: DERM_188685.jpg\n",
      "Processing image 10/100: DERM_195022.jpg\n",
      "Processing image 11/100: DERM_195672.jpg\n",
      "Processing image 12/100: DERM_204464.jpg\n",
      "Processing image 13/100: DERM_216816.jpg\n",
      "Processing image 14/100: DERM_217371.jpg\n",
      "Processing image 15/100: DERM_239326.jpg\n",
      "Processing image 16/100: DERM_244584.jpg\n",
      "Processing image 17/100: DERM_251874.jpg\n",
      "Processing image 18/100: DERM_255498.jpg\n",
      "Processing image 19/100: DERM_260248.jpg\n",
      "Processing image 20/100: DERM_274993.jpg\n",
      "Processing image 21/100: DERM_291844.jpg\n",
      "Processing image 22/100: DERM_296307.jpg\n",
      "Processing image 23/100: DERM_299473.jpg\n",
      "Processing image 24/100: DERM_315007.jpg\n",
      "Processing image 25/100: DERM_316030.jpg\n",
      "Processing image 26/100: DERM_328543.jpg\n",
      "Processing image 27/100: DERM_339062.jpg\n",
      "Processing image 28/100: DERM_339935.jpg\n",
      "Processing image 29/100: DERM_343241.jpg\n",
      "Processing image 30/100: DERM_343616.jpg\n",
      "Processing image 31/100: DERM_345287.jpg\n",
      "Processing image 32/100: DERM_358581.jpg\n",
      "Processing image 33/100: DERM_358662.jpg\n",
      "Processing image 34/100: DERM_368656.jpg\n",
      "Processing image 35/100: DERM_370775.jpg\n",
      "Processing image 36/100: DERM_373563.jpg\n",
      "Processing image 37/100: DERM_380401.jpg\n",
      "Processing image 38/100: DERM_403107.jpg\n",
      "Processing image 39/100: DERM_403317.jpg\n",
      "Processing image 40/100: DERM_423663.jpg\n",
      "Processing image 41/100: DERM_440234.jpg\n",
      "Processing image 42/100: DERM_445377.jpg\n",
      "Processing image 43/100: DERM_451556.jpg\n",
      "Processing image 44/100: DERM_469394.jpg\n",
      "Processing image 45/100: DERM_475350.jpg\n",
      "Processing image 46/100: DERM_476296.jpg\n",
      "Processing image 47/100: DERM_478129.jpg\n",
      "Processing image 48/100: DERM_485376.jpg\n",
      "Processing image 49/100: DERM_491896.jpg\n",
      "Processing image 50/100: DERM_501297.jpg\n",
      "Processing image 51/100: DERM_509552.jpg\n",
      "Processing image 52/100: DERM_520523.jpg\n",
      "Processing image 53/100: DERM_525062.jpg\n",
      "Processing image 54/100: DERM_527212.jpg\n",
      "Processing image 55/100: DERM_532790.jpg\n",
      "Processing image 56/100: DERM_533153.jpg\n",
      "Processing image 57/100: DERM_557126.jpg\n",
      "Processing image 58/100: DERM_588963.jpg\n",
      "Processing image 59/100: DERM_595519.jpg\n",
      "Processing image 60/100: DERM_597858.jpg\n",
      "Processing image 61/100: DERM_639468.jpg\n",
      "Processing image 62/100: DERM_661057.jpg\n",
      "Processing image 63/100: DERM_661490.jpg\n",
      "Processing image 64/100: DERM_663282.jpg\n",
      "Processing image 65/100: DERM_668485.jpg\n",
      "Processing image 66/100: DERM_675007.jpg\n",
      "Processing image 67/100: DERM_677529.jpg\n",
      "Processing image 68/100: DERM_680922.jpg\n",
      "Processing image 69/100: DERM_698013.jpg\n",
      "Processing image 70/100: DERM_714802.jpg\n",
      "Processing image 71/100: DERM_715530.jpg\n",
      "Processing image 72/100: DERM_717933.jpg\n",
      "Processing image 73/100: DERM_729896.jpg\n",
      "Processing image 74/100: DERM_743205.jpg\n",
      "Processing image 75/100: DERM_744042.jpg\n",
      "Processing image 76/100: DERM_749795.jpg\n",
      "Processing image 77/100: DERM_750138.jpg\n",
      "Processing image 78/100: DERM_755315.jpg\n",
      "Processing image 79/100: DERM_765987.jpg\n",
      "Processing image 80/100: DERM_803576.jpg\n",
      "Processing image 81/100: DERM_807136.jpg\n",
      "Processing image 82/100: DERM_812605.jpg\n",
      "Processing image 83/100: DERM_814959.jpg\n",
      "Processing image 84/100: DERM_822769.jpg\n",
      "Processing image 85/100: DERM_823888.jpg\n",
      "Processing image 86/100: DERM_826759.jpg\n",
      "Processing image 87/100: DERM_843665.jpg\n",
      "Processing image 88/100: DERM_858182.jpg\n",
      "Processing image 89/100: DERM_863117.jpg\n",
      "Processing image 90/100: DERM_875449.jpg\n",
      "Processing image 91/100: DERM_892713.jpg\n",
      "Processing image 92/100: DERM_930725.jpg\n",
      "Processing image 93/100: DERM_933078.jpg\n",
      "Processing image 94/100: DERM_944359.jpg\n",
      "Processing image 95/100: DERM_949113.jpg\n",
      "Processing image 96/100: DERM_958367.jpg\n",
      "Processing image 97/100: DERM_960546.jpg\n",
      "Processing image 98/100: DERM_978695.jpg\n",
      "Processing image 99/100: DERM_985566.jpg\n",
      "Processing image 100/100: DERM_985568.jpg\n",
      "\n",
      "Processing complete!\n",
      "Results saved to: skin_lesion_predictions_20250530_073023.xlsx\n",
      "Total images processed: 100\n",
      "\n",
      "Summary:\n",
      "Top 10 most frequent predictions:\n",
      "  jd(melanocytic, benign, dysplastic, junctional, junctional): 9 images\n",
      "  scc(nonmelanocytic, malignant, keratinocytic, keratinocytic, squamous_cell_carcinoma): 9 images\n",
      "  mel(melanocytic, malignant, melanoma, melanoma, melanoma): 7 images\n",
      "  db(melanocytic, benign, banal, dermal, dermal): 6 images\n",
      "  ajb(melanocytic, benign, banal, junctional, acral): 6 images\n",
      "  jb(melanocytic, benign, banal, junctional, junctional): 5 images\n",
      "  ajd(melanocytic, benign, dysplastic, junctional, acral): 5 images\n",
      "  sk(nonmelanocytic, benign, keratinocytic, keratinocytic, seborrheic_keratosis): 4 images\n",
      "  bcc(nonmelanocytic, malignant, keratinocytic, keratinocytic, basal_cell_carcinoma): 4 images\n",
      "  cb(melanocytic, benign, banal, compound, compound): 4 images\n",
      "\n",
      "Showing top 5 predictions:\n",
      "\n",
      "Image: DERM_106035.jpg\n",
      "Top prediction: ha(nonmelanocytic, benign, vascular, vascular, hemangioma) (0.6750)\n",
      "  2. db(melanocytic, benign, banal, dermal, dermal) (0.0649)\n",
      "  3. df(nonmelanocytic, benign, fibro_histiocytic, fibro_histiocytic, dermatofibroma) (0.0581)\n",
      "  4. la(nonmelanocytic, benign, vascular, vascular, lymphangioma) (0.0480)\n",
      "  5. jd(melanocytic, benign, dysplastic, junctional, junctional) (0.0312)\n",
      "\n",
      "Image: DERM_110135.jpg\n",
      "Top prediction: jb(melanocytic, benign, banal, junctional, junctional) (0.9740)\n",
      "  2. jd(melanocytic, benign, dysplastic, junctional, junctional) (0.0260)\n",
      "  3. ls(melanocytic, benign, lentigo, lentigo, lentigo_simplex) (0.0000)\n",
      "  4. sl(melanocytic, benign, lentigo, lentigo, solar_lentigo) (0.0000)\n",
      "  5. df(nonmelanocytic, benign, fibro_histiocytic, fibro_histiocytic, dermatofibroma) (0.0000)\n",
      "\n",
      "Image: DERM_111637.jpg\n",
      "Top prediction: isl(melanocytic, neging, lentigo, lentigo, ink_spot_lentigo) (0.9078)\n",
      "  2. cjb(melanocytic, benign, banal, junctional, congenital) (0.0821)\n",
      "  3. ccb(melanocytic, benign, banal, compound, congenital) (0.0098)\n",
      "  4. bd(nonmelanocytic, malignant, keratinocytic, keratinocytic, bowen_disease) (0.0002)\n",
      "  5. alm(melanocytic, malignant, melanoma, melanoma, acral_lentiginious) (0.0001)\n",
      "\n",
      "Image: DERM_125826.jpg\n",
      "Top prediction: db(melanocytic, benign, banal, dermal, dermal) (0.9673)\n",
      "  2. cb(melanocytic, benign, banal, compound, compound) (0.0241)\n",
      "  3. sk(nonmelanocytic, benign, keratinocytic, keratinocytic, seborrheic_keratosis) (0.0069)\n",
      "  4. ha(nonmelanocytic, benign, vascular, vascular, hemangioma) (0.0010)\n",
      "  5. cd(melanocytic, benign, dysplastic, compound, compound) (0.0002)\n",
      "\n",
      "Image: DERM_131011.jpg\n",
      "Top prediction: mel(melanocytic, malignant, melanoma, melanoma, melanoma) (1.0000)\n",
      "  2. lmm(melanocytic, malignant, melanoma, melanoma, lentigo_maligna_melanoma) (0.0000)\n",
      "  3. alm(melanocytic, malignant, melanoma, melanoma, acral_lentiginious) (0.0000)\n",
      "  4. sk(nonmelanocytic, benign, keratinocytic, keratinocytic, seborrheic_keratosis) (0.0000)\n",
      "  5. ccd(melanocytic, benign, dysplastic, compound, congenital) (0.0000)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the correct model architecture that matches the saved checkpoint\n",
    "class SkinLesionClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=40):  # Updated to 40 classes to match checkpoint\n",
    "        super(SkinLesionClassifier, self).__init__()\n",
    "        # Load ResNet50 and replace the final fc layer with custom layers\n",
    "        resnet = models.resnet50(pretrained=False)\n",
    "        \n",
    "        # Copy all layers except the final fc layer\n",
    "        self.conv1 = resnet.conv1\n",
    "        self.bn1 = resnet.bn1\n",
    "        self.relu = resnet.relu\n",
    "        self.maxpool = resnet.maxpool\n",
    "        self.layer1 = resnet.layer1\n",
    "        self.layer2 = resnet.layer2\n",
    "        self.layer3 = resnet.layer3\n",
    "        self.layer4 = resnet.layer4\n",
    "        self.avgpool = resnet.avgpool\n",
    "        \n",
    "        # Custom fc layers (matching the saved model structure exactly)\n",
    "        # The saved model has fc.0, fc.3, fc.6 as Linear layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2048, 512),      # fc.0 - matches fc.0.weight, fc.0.bias\n",
    "            nn.ReLU(inplace=True),     # fc.1 - ReLU activation\n",
    "            nn.Dropout(0.5),           # fc.2 - Dropout\n",
    "            nn.Linear(512, 256),       # fc.3 - matches fc.3.weight, fc.3.bias  \n",
    "            nn.ReLU(inplace=True),     # fc.4 - ReLU activation\n",
    "            nn.Dropout(0.3),           # fc.5 - Dropout\n",
    "            nn.Linear(256, num_classes)# fc.6 - matches fc.6.weight, fc.6.bias\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Load the model\n",
    "model_path = \"/mnt/c/Users/JakeLee/Desktop/PFE/App/SkinVision-AI/backend/models/resnet50_model.pth\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "\n",
    "# Create model and load state dict\n",
    "model = SkinLesionClassifier()\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "epoch = checkpoint.get('epoch', 'Unknown')\n",
    "val_acc = checkpoint.get('val_acc', 'Unknown')\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded successfully on {device}\")\n",
    "print(f\"Model was saved at epoch: {epoch}\")\n",
    "print(f\"Validation accuracy: {val_acc:.4f}\")\n",
    "\n",
    "# Load class names from classes.txt file\n",
    "def load_class_names():\n",
    "    try:\n",
    "        with open('/mnt/c/Users/JakeLee/Desktop/PFE/App/SkinVision-AI/classes.txt', 'r') as f:\n",
    "            class_names = [line.strip() for line in f.readlines()]\n",
    "        # Ensure we have exactly 40 classes\n",
    "        if len(class_names) == 39:\n",
    "            class_names.append(\"Unknown_Class_40\")  # Add placeholder for missing class\n",
    "            print(\"Warning: Only 39 classes found in classes.txt, added placeholder for 40th class\")\n",
    "        return class_names\n",
    "    except FileNotFoundError:\n",
    "        print(\"classes.txt not found, using default classes\")\n",
    "        # Create 40 default classes\n",
    "        return [f\"Class_{i+1}\" for i in range(40)]\n",
    "\n",
    "class_names = load_class_names()\n",
    "print(f\"Loaded {len(class_names)} class names\")\n",
    "\n",
    "# Define image transformations (adjust based on your training preprocessing)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Function to get available images\n",
    "def get_available_images():\n",
    "    image_dir = \"/mnt/c/Users/JakeLee/Desktop/PFE/ChatGPT-TEST/Images for test\"\n",
    "    if not os.path.exists(image_dir):\n",
    "        print(f\"Directory not found: {image_dir}\")\n",
    "        return [], \"\"\n",
    "    \n",
    "    valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')\n",
    "    images = [f for f in os.listdir(image_dir) if f.lower().endswith(valid_extensions)]\n",
    "    return images, image_dir\n",
    "\n",
    "# Function to predict image and return results\n",
    "def predict_image(image_path):\n",
    "    try:\n",
    "        # Load and preprocess image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Make prediction\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_tensor)\n",
    "            probabilities = torch.nn.functional.softmax(outputs[0], dim=0)\n",
    "            \n",
    "        # Get top 5 predictions\n",
    "        top5_probs, top5_indices = torch.topk(probabilities, 5)\n",
    "        \n",
    "        # Return results as lists\n",
    "        predictions = []\n",
    "        confidences = []\n",
    "        \n",
    "        for prob, idx in zip(top5_probs, top5_indices):\n",
    "            predictions.append(class_names[idx.item()])\n",
    "            confidences.append(prob.item())\n",
    "        \n",
    "        return predictions, confidences\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_path}: {e}\")\n",
    "        return [\"Error\"] * 5, [0.0] * 5\n",
    "\n",
    "# Function to process all images and create Excel file\n",
    "def process_all_images():\n",
    "    images, image_dir = get_available_images()\n",
    "    \n",
    "    if not images:\n",
    "        print(\"No images found in the directory!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Processing {len(images)} images...\")\n",
    "    \n",
    "    # Initialize results list\n",
    "    results = []\n",
    "    \n",
    "    # Process each image\n",
    "    for i, image_name in enumerate(images):\n",
    "        print(f\"Processing image {i+1}/{len(images)}: {image_name}\")\n",
    "        \n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        predictions, confidences = predict_image(image_path)\n",
    "        \n",
    "        # Create row for this image\n",
    "        row = {\n",
    "            'Image_Name': image_name,\n",
    "            'Prediction_1': predictions[0],\n",
    "            'Confidence_1': confidences[0],\n",
    "            'Prediction_2': predictions[1],\n",
    "            'Confidence_2': confidences[1],\n",
    "            'Prediction_3': predictions[2],\n",
    "            'Confidence_3': confidences[2],\n",
    "            'Prediction_4': predictions[3],\n",
    "            'Confidence_4': confidences[3],\n",
    "            'Prediction_5': predictions[4],\n",
    "            'Confidence_5': confidences[4]\n",
    "        }\n",
    "        \n",
    "        results.append(row)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Generate filename with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    excel_filename = f\"skin_lesion_predictions_{timestamp}.xlsx\"\n",
    "    excel_path = f\"/mnt/c/Users/JakeLee/Desktop/PFE/App/SkinVision-AI/{excel_filename}\"\n",
    "    \n",
    "    # Save to Excel\n",
    "    df.to_excel(excel_path, index=False)\n",
    "    \n",
    "    print(f\"\\nProcessing complete!\")\n",
    "    print(f\"Results saved to: {excel_filename}\")\n",
    "    print(f\"Total images processed: {len(images)}\")\n",
    "    \n",
    "    # Display summary statistics\n",
    "    print(\"\\nSummary:\")\n",
    "    top_predictions = df['Prediction_1'].value_counts().head(10)\n",
    "    print(\"Top 10 most frequent predictions:\")\n",
    "    for pred, count in top_predictions.items():\n",
    "        print(f\"  {pred}: {count} images\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to display sample predictions (optional)\n",
    "def show_sample_predictions(df, num_samples=5):\n",
    "    print(f\"\\nShowing top {num_samples} predictions:\")\n",
    "    for i in range(min(num_samples, len(df))):\n",
    "        row = df.iloc[i]\n",
    "        print(f\"\\nImage: {row['Image_Name']}\")\n",
    "        print(f\"Top prediction: {row['Prediction_1']} ({row['Confidence_1']:.4f})\")\n",
    "        for j in range(2, 6):\n",
    "            print(f\"  {j}. {row[f'Prediction_{j}']} ({row[f'Confidence_{j}']:.4f})\")\n",
    "\n",
    "# Run the batch processing\n",
    "results_df = process_all_images()\n",
    "\n",
    "# Show sample results\n",
    "if results_df is not None and len(results_df) > 0:\n",
    "    show_sample_predictions(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
